
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>16. CycleGAN &#8212; Note on Deep Unsupervised Learning</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=4787184b" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="../_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=36754332"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=afe5de03"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'GAN/CycleGAN';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="17. Diffusion models" href="../Diffusion/Diffusion-model.html" />
    <link rel="prev" title="15. Conditional GAN" href="ConditionalGAN.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
  
    <p class="title logo__title">Note on Deep Unsupervised Learning</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Welcome to your Jupyter Book
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">A. Autoregressive model</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../Autoregressive/Autoregressive-models.html">1. Autoregressive models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Autoregressive/CharRNN.html">2. CharRNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Autoregressive/MADE.html">3. MADE</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Autoregressive/PixelCNN.html">4. PixelCNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Autoregressive/iGPT.html">5. Causal transformer: iGPT</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">B. Flow based model</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../Flow/Flow-based-models.html">6. Flow based models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Flow/RealNVP.html">7. Real NVP</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Flow/Glow.html">8. GLOW</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">C. Variational autoencoder</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../VAE/Latent-variable-models.html">9. Latent variable models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../VAE/Convolution-VAE.html">10. Convolutional VAE</a></li>
<li class="toctree-l1"><a class="reference internal" href="../VAE/Conditional-VAE.html">11. Conditional VAE</a></li>
<li class="toctree-l1"><a class="reference internal" href="../VAE/VQVAE.html">12. VQVAE</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">D. Generative adversarial network</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="DCGAN.html">13. DCGAN</a></li>
<li class="toctree-l1"><a class="reference internal" href="WGAN.html">14. Wasserstein GAN</a></li>
<li class="toctree-l1"><a class="reference internal" href="ConditionalGAN.html">15. Conditional GAN</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">16. CycleGAN</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">E. Diffusion model</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../Diffusion/Diffusion-model.html">17. Diffusion models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Diffusion/DDPM.html">18. Denoising diffusion probabilistic model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Diffusion/Classifier-free-guidance.html">19. Classifier free guidance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Diffusion/DiT.html">20. Diffusion transformer</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2FGAN/CycleGAN.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/GAN/CycleGAN.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>CycleGAN</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cycle-consistency-loss">16.1. Cycle consistency loss</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#identity-loss">16.2. Identity loss</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#combined-loss">16.3. Combined loss</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cyclegan-implementation">16.4. CycleGAN implementation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#generator-discriminator-implementation">16.4.1. Generator/Discriminator implementation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-loop-implementation">16.4.2. Training Loop Implementation</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="cyclegan">
<h1><span class="section-number">16. </span>CycleGAN<a class="headerlink" href="#cyclegan" title="Link to this heading">#</a></h1>
<p>The CycleGAN architecture is proposed by Zhu et al. in 2020. Instead of generating images, CycleGAN aims to perform image translation tasks (for example, turning horses into zebras, grayscale images into colored images, summer scenes into winter scenes, etc.).<br></p>
<p>Formally, let <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> and <span class="math notranslate nohighlight">\(\mathcal{Y}\)</span> denote two image domains. We want to learn a mapping <span class="math notranslate nohighlight">\(F: \mathcal{X} \rightarrow \mathcal{Y}\)</span>. This turns images in the source domain <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> into images in the target domain <span class="math notranslate nohighlight">\(\mathcal{Y}\)</span>. However, there are many different ways to map <span class="math notranslate nohighlight">\(X \in \mathcal{X}\)</span> to <span class="math notranslate nohighlight">\(Y \in \mathcal{Y}\)</span>. To constrain the problem, we also learn the inverse mapping <span class="math notranslate nohighlight">\(G: \mathcal{Y} \rightarrow \mathcal{X}\)</span> and impose the cycle consistency constraint</p>
<div class="math notranslate nohighlight">
\[G(F(X))=X\hspace{10mm}F(G(Y))=Y\]</div>
<p>In CycleGAN, the mappings <span class="math notranslate nohighlight">\(F\)</span> and <span class="math notranslate nohighlight">\(G\)</span> are parameterized as two GANs:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(F\)</span> is responsible to converting image in space <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> to image in space <span class="math notranslate nohighlight">\(\mathcal{Y}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(G\)</span> is responsible to converting image in space <span class="math notranslate nohighlight">\(\mathcal{Y}\)</span> to image in space <span class="math notranslate nohighlight">\(\mathcal{X}\)</span></p></li>
<li><p>The discriminator for <span class="math notranslate nohighlight">\(F\)</span>, denoted as <span class="math notranslate nohighlight">\(D_F\)</span>, attempts to detect images generated by <span class="math notranslate nohighlight">\(G\)</span></p></li>
<li><p>The discriminator for <span class="math notranslate nohighlight">\(G\)</span>, denoted as <span class="math notranslate nohighlight">\(D_G\)</span>, attempts to detect images generated by <span class="math notranslate nohighlight">\(F\)</span></p></li>
</ul>
<p>The objective is the combined adversarial loss for the two GANs.</p>
<div class="math notranslate nohighlight">
\[\mathcal{L}(F, G, D_F, D_G) = \mathbb{E}_{x\sim p(x)}[\log (1-D_F(G(x)))]+\mathbb{E}_{y\sim p(y)}[\log D_F(y)]+ \mathbb{E}_{x\sim p(x)}[\log (1-D_G(F(x)))]+\mathbb{E}_{y\sim p(y)}[\log D_G(y)]\]</div>
<p>Intuitively, we want the mapping <span class="math notranslate nohighlight">\(F\)</span> to be able to fool the discriminator <span class="math notranslate nohighlight">\(D_G\)</span>, so that it maps <span class="math notranslate nohighlight">\(X\)</span> to a realistic image <span class="math notranslate nohighlight">\(Y\)</span>. At the same time, we want the discriminator <span class="math notranslate nohighlight">\(D_G\)</span> to be a challenging opponent. The same reasoning applies to the other side.</p>
<section id="cycle-consistency-loss">
<h2><span class="section-number">16.1. </span>Cycle consistency loss<a class="headerlink" href="#cycle-consistency-loss" title="Link to this heading">#</a></h2>
<p>As mentioned before, to constrain the problem, we impose the cycle consistency contraint, which restricts that</p>
<div class="math notranslate nohighlight">
\[G(F(X))=X\hspace{10mm}F(G(Y))=Y\]</div>
<p>The loss associated to this constraint is given by</p>
<div class="math notranslate nohighlight">
\[\mathcal{L}_{cycle}(F, G) = \mathbb{E}_{x\sim p(x)}[\|G(F(x))-x\|_1] + \mathbb{E}_{y\sim p(y)}[\|F(G(y))-y\|_1]\]</div>
<p>In the paper, <span class="math notranslate nohighlight">\(L_1\)</span> norm is used since <span class="math notranslate nohighlight">\(L_2\)</span> norm tend to create blurry images.</p>
</section>
<section id="identity-loss">
<h2><span class="section-number">16.2. </span>Identity loss<a class="headerlink" href="#identity-loss" title="Link to this heading">#</a></h2>
<p>In the paper, the authors added an additional loss: the identity loss. The intuition is that applying <span class="math notranslate nohighlight">\(F\)</span> to images in domain <span class="math notranslate nohighlight">\(\mathcal{Y}\)</span> should just be itself, since <span class="math notranslate nohighlight">\(F\)</span> is supposed to turn images in <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> to <span class="math notranslate nohighlight">\(\mathcal{Y}\)</span>. So essentially we are imposing the constraint that <span class="math notranslate nohighlight">\(F\)</span> is an identity map on <span class="math notranslate nohighlight">\(\mathcal{Y}\)</span>. The same applies for <span class="math notranslate nohighlight">\(G\)</span>. Formally, the identity loss is given by</p>
<div class="math notranslate nohighlight">
\[\mathcal{L}_{identity}(F, G) = \mathbb{E}_{x\sim p(x)}[\|G(x)-x\|_1] + \mathbb{E}_{y\sim p(y)}[\|F(y)-y\|_1]\]</div>
</section>
<section id="combined-loss">
<h2><span class="section-number">16.3. </span>Combined loss<a class="headerlink" href="#combined-loss" title="Link to this heading">#</a></h2>
<p>Finally, the combined loss is CycleGAN is given by</p>
<div class="math notranslate nohighlight">
\[\mathcal{L}({F, G, D_F, D_G}) = \mathcal{L}(F, G, D_F, D_G) + \lambda_{cycle}\mathcal{L}_{cycle}(F, G) + \lambda_{identity}\mathcal{L}_{identity}(F, G) \]</div>
<p>Where <span class="math notranslate nohighlight">\(\lambda_{cycle}, \lambda_{identity}\)</span> are two hyperparameters that controls the impact of consistency and identity loss. The optimization problem is therefore to solve</p>
<div class="math notranslate nohighlight">
\[F^*, G^* = \underset{F, G}{\text{argmin}}\max_{D_F, D_G}\;\mathcal{L}({F, G, D_F, D_G})\]</div>
</section>
<section id="cyclegan-implementation">
<h2><span class="section-number">16.4. </span>CycleGAN implementation<a class="headerlink" href="#cyclegan-implementation" title="Link to this heading">#</a></h2>
<p>Below we implement CycleGAN and test its performance on MNIST/colored MNIST image translation dataset. The dataset is shown below.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">transforms</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">from</span> <span class="nn">torchvision.datasets</span> <span class="kn">import</span> <span class="n">MNIST</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">torchvision.utils</span> <span class="kn">import</span> <span class="n">make_grid</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">random_split</span>
<span class="kn">from</span> <span class="nn">cycleGAN</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">cv2</span>

<span class="n">DEVICE</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>

<span class="n">grayscale_mnist</span><span class="p">,</span> <span class="n">color_mnist</span> <span class="o">=</span> <span class="n">load_mnist</span><span class="p">(</span><span class="s1">&#39;./mnist_data.npy&#39;</span><span class="p">,</span> <span class="s1">&#39;./cmnist_data.npy&#39;</span><span class="p">)</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">GrayscaleAndColoredMNIST</span><span class="p">(</span><span class="n">grayscale_mnist</span><span class="p">,</span> <span class="n">color_mnist</span><span class="p">)</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">train_ratio</span> <span class="o">=</span> <span class="mf">0.8</span>
<span class="n">train_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">train_ratio</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">))</span>
<span class="n">test_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span> <span class="o">-</span> <span class="n">train_size</span>
<span class="n">train_dataset</span><span class="p">,</span> <span class="n">test_dataset</span> <span class="o">=</span> <span class="n">random_split</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="p">[</span><span class="n">train_size</span><span class="p">,</span> <span class="n">test_size</span><span class="p">])</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
<section id="generator-discriminator-implementation">
<h3><span class="section-number">16.4.1. </span>Generator/Discriminator implementation<a class="headerlink" href="#generator-discriminator-implementation" title="Link to this heading">#</a></h3>
<p>We start by implementing the generator/discriminator. We follow a CNN architecture for both generator and discrimintator. The architecture is shown below. We speicifically make the generator strongfer by allowing multiple convolutional block layers.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Generator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Generator</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">3</span><span class="p">),</span>
                    <span class="n">nn</span><span class="o">.</span><span class="n">InstanceNorm2d</span><span class="p">(</span><span class="n">num_features</span><span class="o">=</span><span class="mi">64</span><span class="p">),</span>
                    <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
                    <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
                    <span class="n">nn</span><span class="o">.</span><span class="n">InstanceNorm2d</span><span class="p">(</span><span class="n">num_features</span><span class="o">=</span><span class="mi">128</span><span class="p">),</span>
                    <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
                    <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
                    <span class="n">nn</span><span class="o">.</span><span class="n">InstanceNorm2d</span><span class="p">(</span><span class="n">num_features</span><span class="o">=</span><span class="mi">256</span><span class="p">),</span>
                    <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()]</span>  <span class="c1">## [1, 256, 8, 8]</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_layers</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ResnetBlock</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">256</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
                         <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
                         <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
                         <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
                         <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">3</span><span class="p">),</span>
                         <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">()])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">Discriminator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Discriminator</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
                                 <span class="n">nn</span><span class="o">.</span><span class="n">InstanceNorm2d</span><span class="p">(</span><span class="n">num_features</span><span class="o">=</span><span class="mi">64</span><span class="p">),</span>
                                 <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
                                 <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
                                 <span class="n">nn</span><span class="o">.</span><span class="n">InstanceNorm2d</span><span class="p">(</span><span class="n">num_features</span><span class="o">=</span><span class="mi">128</span><span class="p">),</span>
                                 <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
                                 <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
                                 <span class="n">nn</span><span class="o">.</span><span class="n">InstanceNorm2d</span><span class="p">(</span><span class="n">num_features</span><span class="o">=</span><span class="mi">256</span><span class="p">),</span>
                                 <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
                                 <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
                                 <span class="n">nn</span><span class="o">.</span><span class="n">InstanceNorm2d</span><span class="p">(</span><span class="n">num_features</span><span class="o">=</span><span class="mi">512</span><span class="p">),</span>
                                 <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
                                 <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1">## in: [B, 3, 32, 32]</span>
        <span class="c1">## out: [B, 1]</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="k">class</span> <span class="nc">GAN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GAN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">generator</span> <span class="o">=</span> <span class="n">Generator</span><span class="p">(</span><span class="n">n_layers</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">discriminator</span> <span class="o">=</span> <span class="n">Discriminator</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="training-loop-implementation">
<h3><span class="section-number">16.4.2. </span>Training Loop Implementation<a class="headerlink" href="#training-loop-implementation" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">train_epoch</span><span class="p">(</span><span class="n">model_g</span><span class="p">,</span> <span class="n">model_c</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">,</span> <span class="n">optimizer_disc</span><span class="p">,</span> <span class="n">optimizer_gen</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">lambda_cycle</span><span class="p">,</span> <span class="n">lambda_identity</span><span class="p">,</span> <span class="n">sample</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">):</span>
    <span class="n">model_g</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">model_c</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">model_g</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">model_c</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">train_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">x_g</span><span class="p">,</span> <span class="n">x_c</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
        <span class="n">x_g</span><span class="p">,</span> <span class="n">x_c</span> <span class="o">=</span> <span class="n">x_g</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">x_c</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">x_g</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1">## Train Discriminator </span>
        <span class="n">optimizer_disc</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="c1">## Discriminator loss for grayscale</span>
        <span class="n">loss_g_real_disc</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">model_g</span><span class="o">.</span><span class="n">discriminator</span><span class="p">(</span><span class="n">x_g</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
        <span class="n">loss_g_fake_disc</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">model_g</span><span class="o">.</span><span class="n">discriminator</span><span class="p">(</span><span class="n">model_g</span><span class="o">.</span><span class="n">generator</span><span class="p">(</span><span class="n">x_c</span><span class="p">)),</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>

        <span class="c1">## Discriminator loss for color</span>
        <span class="n">loss_c_real_disc</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">model_c</span><span class="o">.</span><span class="n">discriminator</span><span class="p">(</span><span class="n">x_c</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
        <span class="n">loss_c_fake_disc</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">model_c</span><span class="o">.</span><span class="n">discriminator</span><span class="p">(</span><span class="n">model_c</span><span class="o">.</span><span class="n">generator</span><span class="p">(</span><span class="n">x_g</span><span class="p">)),</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>

        <span class="c1">## Compute discriminator loss</span>
        <span class="n">loss_disc</span> <span class="o">=</span> <span class="p">(</span><span class="n">loss_g_real_disc</span> <span class="o">+</span> <span class="n">loss_g_fake_disc</span> <span class="o">+</span> <span class="n">loss_c_real_disc</span> <span class="o">+</span> <span class="n">loss_c_fake_disc</span><span class="p">)</span> <span class="o">/</span> <span class="mi">4</span>
        <span class="n">loss_disc</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer_disc</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
  
        <span class="c1">## Train Generator</span>
        <span class="n">optimizer_gen</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="c1">## Generator loss</span>
        <span class="n">loss_g_fake_gen</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">model_g</span><span class="o">.</span><span class="n">discriminator</span><span class="p">(</span><span class="n">model_g</span><span class="o">.</span><span class="n">generator</span><span class="p">(</span><span class="n">x_c</span><span class="p">)),</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
        <span class="n">loss_c_fake_gen</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">model_c</span><span class="o">.</span><span class="n">discriminator</span><span class="p">(</span><span class="n">model_c</span><span class="o">.</span><span class="n">generator</span><span class="p">(</span><span class="n">x_g</span><span class="p">)),</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>

        <span class="c1">## Cycle consistency loss</span>
        <span class="n">loss_cycle_g</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">l1_loss</span><span class="p">(</span><span class="n">x_g</span><span class="p">,</span> <span class="n">model_g</span><span class="o">.</span><span class="n">generator</span><span class="p">(</span><span class="n">model_c</span><span class="o">.</span><span class="n">generator</span><span class="p">(</span><span class="n">x_g</span><span class="p">)))</span>
        <span class="n">loss_cycle_c</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">l1_loss</span><span class="p">(</span><span class="n">x_c</span><span class="p">,</span> <span class="n">model_c</span><span class="o">.</span><span class="n">generator</span><span class="p">(</span><span class="n">model_g</span><span class="o">.</span><span class="n">generator</span><span class="p">(</span><span class="n">x_c</span><span class="p">)))</span>

        <span class="c1">## Identity loss</span>
        <span class="n">loss_identity_g</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">l1_loss</span><span class="p">(</span><span class="n">x_g</span><span class="p">,</span> <span class="n">model_g</span><span class="o">.</span><span class="n">generator</span><span class="p">(</span><span class="n">x_g</span><span class="p">))</span>
        <span class="n">loss_identity_c</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">l1_loss</span><span class="p">(</span><span class="n">x_c</span><span class="p">,</span> <span class="n">model_c</span><span class="o">.</span><span class="n">generator</span><span class="p">(</span><span class="n">x_c</span><span class="p">))</span>

        <span class="n">loss_gen</span> <span class="o">=</span> <span class="p">(</span><span class="n">loss_g_fake_gen</span> <span class="o">+</span> <span class="n">loss_c_fake_gen</span><span class="p">)</span> <span class="o">+</span> <span class="n">lambda_cycle</span> <span class="o">*</span> <span class="p">(</span><span class="n">loss_cycle_g</span> <span class="o">+</span> <span class="n">loss_cycle_c</span><span class="p">)</span> <span class="o">+</span> <span class="n">lambda_identity</span> <span class="o">*</span> <span class="p">(</span><span class="n">loss_identity_g</span> <span class="o">+</span> <span class="n">loss_identity_c</span><span class="p">)</span>
        <span class="n">loss_gen</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer_gen</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss_disc</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">+</span> <span class="n">loss_gen</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">train_loss</span>
</pre></div>
</div>
</div>
</div>
<p>We created two GANS, each with <span class="math notranslate nohighlight">\(1\)</span> layers of ResNet block. The cycle consistency parameter <span class="math notranslate nohighlight">\(\lambda_{cycle}\)</span> and the identity parameter <span class="math notranslate nohighlight">\(\lambda_{identity}\)</span> is set to <span class="math notranslate nohighlight">\(10\)</span>. We train the model for <span class="math notranslate nohighlight">\(20\)</span> epochs using Adam optimizer with learning rate of <span class="math notranslate nohighlight">\(10^{-3}\)</span> and beta <span class="math notranslate nohighlight">\((0.5, 0.999)\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_g</span> <span class="o">=</span> <span class="n">GAN</span><span class="p">(</span><span class="n">n_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">model_c</span> <span class="o">=</span> <span class="n">GAN</span><span class="p">(</span><span class="n">n_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">lambda_cycle</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">lambda_identity</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">n_epochs</span><span class="o">=</span><span class="mi">10</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCEWithLogitsLoss</span><span class="p">()</span>
<span class="n">optimizer_disc</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">model_g</span><span class="o">.</span><span class="n">discriminator</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">model_c</span><span class="o">.</span><span class="n">discriminator</span><span class="o">.</span><span class="n">parameters</span><span class="p">()),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">))</span>
<span class="n">optimizer_gen</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">model_g</span><span class="o">.</span><span class="n">generator</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">model_c</span><span class="o">.</span><span class="n">generator</span><span class="o">.</span><span class="n">parameters</span><span class="p">()),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">))</span>
<span class="n">train</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">,</span> <span class="n">model_g</span><span class="p">,</span> <span class="n">model_c</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">,</span> <span class="n">optimizer_disc</span><span class="p">,</span> <span class="n">optimizer_gen</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">lambda_cycle</span><span class="p">,</span> <span class="n">lambda_identity</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Below, we plot the results of converting a grayscale image to a colored image, and then back to grayscale. In the subsequent plot, we show the reverse process: converting a colored image to grayscale and then back to color. Note that the model successfully handles image conversions between different domains.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_grayscale_to_color</span><span class="p">(</span><span class="n">model_g</span><span class="p">,</span> <span class="n">model_c</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../_images/6d03d51ba59033e6f32d997d955c9ea88f10f839059f6809205e86dda3313ce7.png" src="../_images/6d03d51ba59033e6f32d997d955c9ea88f10f839059f6809205e86dda3313ce7.png" />
</div>
</div>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_color_to_grayscale</span><span class="p">(</span><span class="n">model_g</span><span class="p">,</span> <span class="n">model_c</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../_images/cffd381222de8a8522f4f4468ec5d742a2455477b1aefa62dc88441a1ffd5249.png" src="../_images/cffd381222de8a8522f4f4468ec5d742a2455477b1aefa62dc88441a1ffd5249.png" />
</div>
</div>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./GAN"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="ConditionalGAN.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">15. </span>Conditional GAN</p>
      </div>
    </a>
    <a class="right-next"
       href="../Diffusion/Diffusion-model.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">17. </span>Diffusion models</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cycle-consistency-loss">16.1. Cycle consistency loss</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#identity-loss">16.2. Identity loss</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#combined-loss">16.3. Combined loss</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cyclegan-implementation">16.4. CycleGAN implementation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#generator-discriminator-implementation">16.4.1. Generator/Discriminator implementation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-loop-implementation">16.4.2. Training Loop Implementation</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Raymond Tsao
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
       Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>